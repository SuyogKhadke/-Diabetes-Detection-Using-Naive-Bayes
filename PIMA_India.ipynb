{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af5c6d9",
   "metadata": {},
   "source": [
    "## 1. Handling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8047b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the neccesery libs. \n",
    "import csv\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82aa312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining Load CSV File\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(r'C:/Users/win/Desktop/diabetes.csv')) #taking each row in the CSV file \n",
    "    dataset = list(lines)#putiing each line as a element in the list in order to access it easily\n",
    "    for i in range(len(dataset)):\n",
    "            dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "575e3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset,splitRatio):\n",
    "    trainSize = int(len(dataset)*splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while(len(trainSet)<trainSize): #we know why we are doing this\n",
    "        index = random.randrange(len(copy)) #taking random sample for training\n",
    "        trainSet.append(copy.pop(index)) # putting it in the trainset and reaming is testSet\n",
    "    return [trainSet,copy] #now the reaming copy is nothing but our testing set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600f8fe",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Summarizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cccb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separatedByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if(vector[-1] not in separated):\n",
    "            separated[vector[-1]]=[]   #if not in the part of class\n",
    "        separated[vector[-1]].append(vector) #merge all the things if part of class will get into Class A and Class B will be blank\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9787e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))  #simply taking avg of numbers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c54f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1) #taking the variaance\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f23e10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute),stdev(attribute)) for attribute in zip(*dataset)] #we are getting summary of dataset as mean and variance\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61c924bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset): #getting summeries by class in this function\n",
    "    separated = separatedByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue,instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa759f3",
   "metadata": {},
   "source": [
    "##  3. Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73f6fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x,mean,stdev): #using the formula for normal distrubtion we are getting Likelihood here \n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1/(math.sqrt(2*math.pi)*stdev))*exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d9f8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbability(summaries,inputVector): #we are doing the denomintor part p(x) <- this thing from Bayes's formula\n",
    "    probabilities = {}\n",
    "    for classValue, classSumaries in summaries.items():\n",
    "        probabilities[classValue] =1\n",
    "        for i in range(len(classSumaries)):\n",
    "            mean,stdev = classSumaries[i]\n",
    "            x  = inputVector[i]\n",
    "            probabilities[classValue]*= calculateProbability(x,mean,stdev)\n",
    "        return probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ace5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries,inputVector): #we are getting which is bestlable we got\n",
    "    probabilities =  calculateClassProbability(summaries,inputVector)\n",
    "    bestLabel, bestProb = None,-1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "963e9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(summaries,testSet): #We are getting prediction of all the test set here\n",
    "    prediction =[]\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries,testSet[i])\n",
    "        prediction.append(result)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb568c8",
   "metadata": {},
   "source": [
    "## 4. Getting Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0dcc3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet,prediction):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == prediction[x]:\n",
    "            correct+=1\n",
    "    return (correct/float(len(testSet)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19948548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows \n",
      "Accuracy: 67.32283464566929 %\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filename='PIMA Dataset'\n",
    "    splitRatio = 0.67\n",
    "    dataset= loadCsv(filename)\n",
    "    trainingSet,testSet = splitDataset(dataset,splitRatio)\n",
    "    print('Split {0} rows into train={1} and test={2} rows '.format(len(dataset),len(trainingSet),len(testSet)))\n",
    "    #preparing Model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    #testing\n",
    "    predictions = getPrediction(summaries,testSet)\n",
    "    accuracy = getAccuracy(testSet,predictions)\n",
    "    print('Accuracy: {0} %'.format(accuracy))\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
